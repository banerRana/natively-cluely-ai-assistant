/**
 * RestSTT - REST-based Speech-to-Text for Groq and OpenAI Whisper
 *
 * Implements the same EventEmitter interface as GoogleSTT:
 *   Events: 'transcript' ({ text, isFinal, confidence }), 'error' (Error)
 *   Methods: start(), stop(), write(chunk: Buffer)
 *
 * Buffers raw PCM chunks, prepends a WAV header, and uploads via REST every ~3 seconds.
 */

import { EventEmitter } from 'events';
import axios from 'axios';
import FormData from 'form-data';

export type RestSttProvider = 'groq' | 'openai';

interface RestSttProviderConfig {
    endpoint: string;
    model: string;
    authHeader: Record<string, string>;
    extraFormFields?: Record<string, string>;
}

const PROVIDER_CONFIGS: Record<RestSttProvider, (apiKey: string) => RestSttProviderConfig> = {
    groq: (apiKey) => ({
        endpoint: 'https://api.groq.com/openai/v1/audio/transcriptions',
        model: 'whisper-large-v3-turbo',
        authHeader: { Authorization: `Bearer ${apiKey}` },
        extraFormFields: {
            temperature: '0',
            response_format: 'json',
            language: 'en',
        },
    }),
    openai: (apiKey) => ({
        endpoint: 'https://api.openai.com/v1/audio/transcriptions',
        model: 'whisper-1',
        authHeader: { Authorization: `Bearer ${apiKey}` },
    }),
};

// Minimum buffer size before sending (avoid sending tiny fragments)
// 16kHz * 2 bytes/sample * 1 channel * 0.5 seconds = 16000 bytes
const MIN_BUFFER_BYTES = 16000;

// Upload interval in milliseconds
const UPLOAD_INTERVAL_MS = 3000;

// Silence threshold - if RMS is below this, skip the upload
const SILENCE_RMS_THRESHOLD = 50;

export class RestSTT extends EventEmitter {
    private provider: RestSttProvider;
    private apiKey: string;
    private config: RestSttProviderConfig;

    private chunks: Buffer[] = [];
    private totalBufferedBytes = 0;
    private uploadTimer: NodeJS.Timeout | null = null;
    private isActive = false;
    private isUploading = false;

    // Audio config (must match SystemAudioCapture output)
    private sampleRate = 16000;
    private numChannels = 1;
    private bitsPerSample = 16;

    constructor(provider: RestSttProvider, apiKey: string, modelOverride?: string) {
        super();
        this.provider = provider;
        this.apiKey = apiKey;
        this.config = PROVIDER_CONFIGS[provider](apiKey);
        if (modelOverride) {
            this.config.model = modelOverride;
        }
        console.log(`[RestSTT] Initialized for provider: ${provider}, model: ${this.config.model}`);
    }

    /**
     * Update API key (e.g., when user saves a new key)
     */
    public setApiKey(apiKey: string): void {
        this.apiKey = apiKey;
        this.config = PROVIDER_CONFIGS[this.provider](apiKey);
        console.log(`[RestSTT] API key updated for ${this.provider}`);
    }

    /**
     * Update sample rate to match the audio source
     */
    public setSampleRate(rate: number): void {
        if (this.sampleRate === rate) return;
        console.log(`[RestSTT] Updating sample rate to ${rate}Hz`);
        this.sampleRate = rate;
    }

    /**
     * Update channel count
     */
    public setAudioChannelCount(count: number): void {
        if (this.numChannels === count) return;
        console.log(`[RestSTT] Updating channel count to ${count}`);
        this.numChannels = count;
    }

    /**
     * No-op for RestSTT (language is handled by the REST API)
     */
    public setRecognitionLanguage(_key: string): void {
        // REST providers handle language automatically or via config
        console.log(`[RestSTT] setRecognitionLanguage called (no-op for REST)`);
    }

    /**
     * No-op for RestSTT (no Google credentials needed)
     */
    public setCredentials(_keyFilePath: string): void {
        console.log(`[RestSTT] setCredentials called (no-op for REST provider)`);
    }

    /**
     * Start the upload timer
     */
    public start(): void {
        if (this.isActive) return;

        console.log(`[RestSTT] Starting (${this.provider})...`);
        this.isActive = true;
        this.chunks = [];
        this.totalBufferedBytes = 0;

        this.uploadTimer = setInterval(() => {
            this.flushAndUpload();
        }, UPLOAD_INTERVAL_MS);
    }

    /**
     * Stop the upload timer and flush remaining buffer
     */
    public stop(): void {
        if (!this.isActive) return;

        console.log(`[RestSTT] Stopping (${this.provider})...`);
        this.isActive = false;

        if (this.uploadTimer) {
            clearInterval(this.uploadTimer);
            this.uploadTimer = null;
        }

        // Flush remaining audio
        this.flushAndUpload();
    }

    /**
     * Write raw PCM audio data to the internal buffer
     */
    public write(audioData: Buffer): void {
        if (!this.isActive) return;
        this.chunks.push(audioData);
        this.totalBufferedBytes += audioData.length;
    }

    /**
     * Concatenate buffered chunks, add WAV header, and upload to REST API
     */
    private async flushAndUpload(): Promise<void> {
        // Skip if no data or already uploading
        if (this.chunks.length === 0 || this.totalBufferedBytes < MIN_BUFFER_BYTES) return;
        if (this.isUploading) return;

        // Grab current buffer and reset
        const currentChunks = this.chunks;
        this.chunks = [];
        const currentBytes = this.totalBufferedBytes;
        this.totalBufferedBytes = 0;

        // Concatenate all chunks
        const rawPcm = Buffer.concat(currentChunks);

        // Check for silence (skip upload if audio is too quiet)
        if (this.isSilent(rawPcm)) {
            if (Math.random() < 0.1) {
                console.log(`[RestSTT] Skipping silent buffer (${rawPcm.length} bytes)`);
            }
            return;
        }

        // Add WAV header
        const wavBuffer = this.addWavHeader(rawPcm, this.sampleRate);

        this.isUploading = true;

        try {
            const transcript = await this.uploadAudio(wavBuffer);

            if (transcript && transcript.trim().length > 0) {
                console.log(`[RestSTT] Transcript: "${transcript.substring(0, 60)}..."`);
                this.emit('transcript', {
                    text: transcript.trim(),
                    isFinal: true,
                    confidence: 1.0,
                });
            }
        } catch (err) {
            console.error(`[RestSTT] Upload error:`, err);
            this.emit('error', err instanceof Error ? err : new Error(String(err)));
        } finally {
            this.isUploading = false;
        }
    }

    /**
     * Upload WAV audio to the REST endpoint
     */
    private async uploadAudio(wavBuffer: Buffer): Promise<string> {
        const form = new FormData();

        // Append audio file
        form.append('file', wavBuffer, {
            filename: 'audio.wav',
            contentType: 'audio/wav',
        });

        // Append model
        form.append('model', this.config.model);

        // Append extra form fields if any
        if (this.config.extraFormFields) {
            for (const [key, value] of Object.entries(this.config.extraFormFields)) {
                form.append(key, value);
            }
        }

        const response = await axios.post(this.config.endpoint, form, {
            headers: {
                ...this.config.authHeader,
                ...form.getHeaders(),
            },
            timeout: 30000, // 30 second timeout
        });

        // Extract text from response
        const data = response.data;

        if (typeof data === 'string') {
            return data;
        }

        if (data && typeof data.text === 'string') {
            return data.text;
        }

        console.warn(`[RestSTT] Unexpected response format:`, data);
        return '';
    }

    /**
     * Check if audio buffer is essentially silence
     */
    private isSilent(pcmBuffer: Buffer): boolean {
        let sum = 0;
        const step = 20; // Sample every 20th sample for speed
        let count = 0;

        for (let i = 0; i < pcmBuffer.length - 1; i += 2 * step) {
            const sample = pcmBuffer.readInt16LE(i);
            sum += sample * sample;
            count++;
        }

        if (count === 0) return true;
        const rms = Math.sqrt(sum / count);
        return rms < SILENCE_RMS_THRESHOLD;
    }

    /**
     * Add a WAV RIFF header to raw PCM data
     * Critical: Groq and OpenAI require a valid WAV file, NOT raw PCM
     */
    private addWavHeader(samples: Buffer, sampleRate: number = 16000): Buffer {
        const buffer = Buffer.alloc(44 + samples.length);
        // RIFF chunk descriptor
        buffer.write('RIFF', 0);
        buffer.writeUInt32LE(36 + samples.length, 4);
        buffer.write('WAVE', 8);
        // fmt sub-chunk
        buffer.write('fmt ', 12);
        buffer.writeUInt32LE(16, 16); // Subchunk1Size (16 for PCM)
        buffer.writeUInt16LE(1, 20);  // AudioFormat (1 = PCM)
        buffer.writeUInt16LE(this.numChannels, 22);  // NumChannels
        buffer.writeUInt32LE(sampleRate, 24); // SampleRate
        buffer.writeUInt32LE(sampleRate * this.numChannels * (this.bitsPerSample / 8), 28); // ByteRate
        buffer.writeUInt16LE(this.numChannels * (this.bitsPerSample / 8), 32); // BlockAlign
        buffer.writeUInt16LE(this.bitsPerSample, 34); // BitsPerSample
        // data sub-chunk
        buffer.write('data', 36);
        buffer.writeUInt32LE(samples.length, 40);
        // Copy raw PCM data
        samples.copy(buffer, 44);

        return buffer;
    }
}
